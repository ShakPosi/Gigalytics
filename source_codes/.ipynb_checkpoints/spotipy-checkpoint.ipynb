{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/plamere/spotipy/tree/master/examples\n",
    "\n",
    "import sys\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "\n",
    "SPOTIPY_CLIENT_ID='af7f8c950718423794701bd8cf073d76'\n",
    "SPOTIPY_CLIENT_SECRET='35f74d86eb5745c394f46b22ed40a9c4'\n",
    "\n",
    "#Mahyar\n",
    "SPOTIPY_CLIENT_ID='cf10232b7c464964b989b45aa956eef4'\n",
    "SPOTIPY_CLIENT_SECRET='ceb6022282354d7082e7055fdda4c647'\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "#remember to reference this project https://github.com/metabrainz/mbspotify\n",
    "import spotify2musicbrainz as mbSpot\n",
    "#remember to reference this project - https://github.com/kelvingakuo/fycharts\n",
    "from fycharts import SpotifyCharts, compute_dates, write_to_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weeklyDates = compute_dates.whatDates('2019-03-01', '2020-02-29', 'top200Weekly')\n",
    "#weeklyDates = compute_dates.defaultListOfDates('isWeekly', 'isViral')\n",
    "DatesAndRegions = compute_dates.returnDatesAndRegions('2019-03-01', '2020-02-29',theRegs=['gb'], isWeekly=True)\n",
    "\n",
    "\n",
    "weeklyDates = DatesAndRegions['dates']\n",
    "region = DatesAndRegions['region']\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fycharts.SpotifyCharts import SpotifyCharts\n",
    "api = SpotifyCharts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fychart api top200weekly pools charts data from spotifycharts.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def pandasToCSV(df, ds): \n",
    "    \n",
    "   \n",
    "    #dt = datetime.today().strftime('%Y%m%d%H%M%S') #%H:%M:%S\n",
    "    csv_filename = \"../datasets/\" + ds+\".csv\"    \n",
    "    #../datasets/\n",
    "    # if file does not exist write header \n",
    "    if not os.path.isfile(csv_filename):\n",
    "        #df.to_csv('filename.csv', header='column_names')\n",
    "        df.to_csv(csv_filename, encoding='utf-8', index=False)   \n",
    "    else: # else if exists, append without the header\n",
    "        df.to_csv(csv_filename, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 24/03/2020 08:15:59 PM : Extracting top 200 weekly for 2019-03-01--2019-03-08 - gb\n",
      "INFO : 24/03/2020 08:16:01 PM : Extracting top 200 weekly for 2019-03-01--2019-03-08 - global\n",
      "INFO : 24/03/2020 08:16:01 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:01 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:03 PM : Extracting top 200 weekly for 2019-03-08--2019-03-15 - gb\n",
      "INFO : 24/03/2020 08:16:03 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:03 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:05 PM : Extracting top 200 weekly for 2019-03-08--2019-03-15 - global\n",
      "INFO : 24/03/2020 08:16:05 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:05 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:10 PM : Extracting top 200 weekly for 2019-03-15--2019-03-22 - gb\n",
      "INFO : 24/03/2020 08:16:10 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:10 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:12 PM : Extracting top 200 weekly for 2019-03-15--2019-03-22 - global\n",
      "INFO : 24/03/2020 08:16:12 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:12 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:14 PM : Extracting top 200 weekly for 2019-03-22--2019-03-29 - gb\n",
      "INFO : 24/03/2020 08:16:14 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:14 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:16 PM : Extracting top 200 weekly for 2019-03-22--2019-03-29 - global\n",
      "INFO : 24/03/2020 08:16:16 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:16 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:18 PM : Extracting top 200 weekly for 2019-03-29--2019-04-05 - gb\n",
      "INFO : 24/03/2020 08:16:18 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:18 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:20 PM : Extracting top 200 weekly for 2019-03-29--2019-04-05 - global\n",
      "INFO : 24/03/2020 08:16:20 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:20 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:22 PM : Extracting top 200 weekly for 2019-04-05--2019-04-12 - gb\n",
      "INFO : 24/03/2020 08:16:22 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:22 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:23 PM : Extracting top 200 weekly for 2019-04-05--2019-04-12 - global\n",
      "INFO : 24/03/2020 08:16:24 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:24 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:25 PM : Extracting top 200 weekly for 2019-04-12--2019-04-19 - gb\n",
      "INFO : 24/03/2020 08:16:25 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:25 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:27 PM : Extracting top 200 weekly for 2019-04-12--2019-04-19 - global\n",
      "INFO : 24/03/2020 08:16:27 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:27 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:29 PM : Extracting top 200 weekly for 2019-04-19--2019-04-26 - gb\n",
      "INFO : 24/03/2020 08:16:29 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:29 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:31 PM : Extracting top 200 weekly for 2019-04-19--2019-04-26 - global\n",
      "INFO : 24/03/2020 08:16:31 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:31 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:33 PM : Extracting top 200 weekly for 2019-04-26--2019-05-03 - gb\n",
      "INFO : 24/03/2020 08:16:33 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:33 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:35 PM : Extracting top 200 weekly for 2019-04-26--2019-05-03 - global\n",
      "INFO : 24/03/2020 08:16:35 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:35 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:36 PM : Extracting top 200 weekly for 2019-05-03--2019-05-10 - gb\n",
      "INFO : 24/03/2020 08:16:36 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:36 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:39 PM : Extracting top 200 weekly for 2019-05-03--2019-05-10 - global\n",
      "INFO : 24/03/2020 08:16:39 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:39 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:41 PM : Extracting top 200 weekly for 2019-05-10--2019-05-17 - gb\n",
      "INFO : 24/03/2020 08:16:41 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:41 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:43 PM : Extracting top 200 weekly for 2019-05-10--2019-05-17 - global\n",
      "INFO : 24/03/2020 08:16:43 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:43 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:45 PM : Extracting top 200 weekly for 2019-05-17--2019-05-24 - gb\n",
      "INFO : 24/03/2020 08:16:45 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:45 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:46 PM : Extracting top 200 weekly for 2019-05-17--2019-05-24 - global\n",
      "INFO : 24/03/2020 08:16:46 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:46 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:48 PM : Extracting top 200 weekly for 2019-05-24--2019-05-31 - gb\n",
      "INFO : 24/03/2020 08:16:48 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:48 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:50 PM : Extracting top 200 weekly for 2019-05-24--2019-05-31 - global\n",
      "INFO : 24/03/2020 08:16:50 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:50 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:52 PM : Extracting top 200 weekly for 2019-05-31--2019-06-07 - gb\n",
      "INFO : 24/03/2020 08:16:52 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:52 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:53 PM : Extracting top 200 weekly for 2019-05-31--2019-06-07 - global\n",
      "INFO : 24/03/2020 08:16:53 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:53 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:55 PM : Extracting top 200 weekly for 2019-06-07--2019-06-14 - gb\n",
      "INFO : 24/03/2020 08:16:55 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:55 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:57 PM : Extracting top 200 weekly for 2019-06-07--2019-06-14 - global\n",
      "INFO : 24/03/2020 08:16:57 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:57 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:16:59 PM : Extracting top 200 weekly for 2019-06-14--2019-06-21 - gb\n",
      "INFO : 24/03/2020 08:16:59 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:16:59 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:01 PM : Extracting top 200 weekly for 2019-06-14--2019-06-21 - global\n",
      "INFO : 24/03/2020 08:17:01 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:01 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:04 PM : Extracting top 200 weekly for 2019-06-21--2019-06-28 - gb\n",
      "INFO : 24/03/2020 08:17:04 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:04 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:06 PM : Extracting top 200 weekly for 2019-06-21--2019-06-28 - global\n",
      "INFO : 24/03/2020 08:17:06 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:06 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:08 PM : Extracting top 200 weekly for 2019-06-28--2019-07-05 - gb\n",
      "INFO : 24/03/2020 08:17:08 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:08 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:10 PM : Extracting top 200 weekly for 2019-06-28--2019-07-05 - global\n",
      "INFO : 24/03/2020 08:17:10 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:10 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:12 PM : Extracting top 200 weekly for 2019-07-05--2019-07-12 - gb\n",
      "INFO : 24/03/2020 08:17:12 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:12 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:15 PM : Extracting top 200 weekly for 2019-07-05--2019-07-12 - global\n",
      "INFO : 24/03/2020 08:17:15 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:15 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:20 PM : Extracting top 200 weekly for 2019-07-12--2019-07-19 - gb\n",
      "INFO : 24/03/2020 08:17:20 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:20 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:25 PM : Extracting top 200 weekly for 2019-07-12--2019-07-19 - global\n",
      "INFO : 24/03/2020 08:17:25 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:25 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:30 PM : Extracting top 200 weekly for 2019-07-19--2019-07-26 - gb\n",
      "INFO : 24/03/2020 08:17:30 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:30 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:33 PM : Extracting top 200 weekly for 2019-07-19--2019-07-26 - global\n",
      "INFO : 24/03/2020 08:17:34 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:34 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:36 PM : Extracting top 200 weekly for 2019-07-26--2019-08-02 - gb\n",
      "INFO : 24/03/2020 08:17:36 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:36 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:40 PM : Extracting top 200 weekly for 2019-07-26--2019-08-02 - global\n",
      "INFO : 24/03/2020 08:17:40 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:40 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:42 PM : Extracting top 200 weekly for 2019-08-02--2019-08-09 - gb\n",
      "INFO : 24/03/2020 08:17:42 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:42 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:44 PM : Extracting top 200 weekly for 2019-08-02--2019-08-09 - global\n",
      "INFO : 24/03/2020 08:17:44 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:44 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:46 PM : Extracting top 200 weekly for 2019-08-09--2019-08-16 - gb\n",
      "INFO : 24/03/2020 08:17:46 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:46 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:48 PM : Extracting top 200 weekly for 2019-08-09--2019-08-16 - global\n",
      "INFO : 24/03/2020 08:17:48 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:48 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:49 PM : Extracting top 200 weekly for 2019-08-16--2019-08-23 - gb\n",
      "INFO : 24/03/2020 08:17:49 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:49 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:52 PM : Extracting top 200 weekly for 2019-08-16--2019-08-23 - global\n",
      "INFO : 24/03/2020 08:17:52 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:52 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:54 PM : Extracting top 200 weekly for 2019-08-23--2019-08-30 - gb\n",
      "INFO : 24/03/2020 08:17:54 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:54 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:56 PM : Extracting top 200 weekly for 2019-08-23--2019-08-30 - global\n",
      "INFO : 24/03/2020 08:17:56 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:56 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:57 PM : Extracting top 200 weekly for 2019-08-30--2019-09-06 - gb\n",
      "INFO : 24/03/2020 08:17:57 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:57 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:17:59 PM : Extracting top 200 weekly for 2019-08-30--2019-09-06 - global\n",
      "INFO : 24/03/2020 08:17:59 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:17:59 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:00 PM : Extracting top 200 weekly for 2019-09-06--2019-09-13 - gb\n",
      "INFO : 24/03/2020 08:18:00 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:00 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:02 PM : Extracting top 200 weekly for 2019-09-06--2019-09-13 - global\n",
      "INFO : 24/03/2020 08:18:02 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:02 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:04 PM : Extracting top 200 weekly for 2019-09-13--2019-09-20 - gb\n",
      "INFO : 24/03/2020 08:18:04 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:04 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:05 PM : Extracting top 200 weekly for 2019-09-13--2019-09-20 - global\n",
      "INFO : 24/03/2020 08:18:05 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:05 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:07 PM : Extracting top 200 weekly for 2019-09-20--2019-09-27 - gb\n",
      "INFO : 24/03/2020 08:18:07 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:07 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:09 PM : Extracting top 200 weekly for 2019-09-20--2019-09-27 - global\n",
      "INFO : 24/03/2020 08:18:09 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:09 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:10 PM : Extracting top 200 weekly for 2019-09-27--2019-10-04 - gb\n",
      "INFO : 24/03/2020 08:18:10 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:10 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:12 PM : Extracting top 200 weekly for 2019-09-27--2019-10-04 - global\n",
      "INFO : 24/03/2020 08:18:12 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:12 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:14 PM : Extracting top 200 weekly for 2019-10-04--2019-10-11 - gb\n",
      "INFO : 24/03/2020 08:18:14 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:14 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:16 PM : Extracting top 200 weekly for 2019-10-04--2019-10-11 - global\n",
      "INFO : 24/03/2020 08:18:16 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:16 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:18 PM : Extracting top 200 weekly for 2019-10-11--2019-10-18 - gb\n",
      "INFO : 24/03/2020 08:18:18 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:18 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:20 PM : Extracting top 200 weekly for 2019-10-11--2019-10-18 - global\n",
      "INFO : 24/03/2020 08:18:20 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:20 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:21 PM : Extracting top 200 weekly for 2019-10-18--2019-10-25 - gb\n",
      "INFO : 24/03/2020 08:18:21 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:21 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:23 PM : Extracting top 200 weekly for 2019-10-18--2019-10-25 - global\n",
      "INFO : 24/03/2020 08:18:23 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:23 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:26 PM : Extracting top 200 weekly for 2019-10-25--2019-11-01 - gb\n",
      "INFO : 24/03/2020 08:18:26 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:26 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:29 PM : Extracting top 200 weekly for 2019-10-25--2019-11-01 - global\n",
      "INFO : 24/03/2020 08:18:29 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:29 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:31 PM : Extracting top 200 weekly for 2019-11-01--2019-11-08 - gb\n",
      "INFO : 24/03/2020 08:18:31 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:31 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:32 PM : Extracting top 200 weekly for 2019-11-01--2019-11-08 - global\n",
      "INFO : 24/03/2020 08:18:32 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:32 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:34 PM : Extracting top 200 weekly for 2019-11-08--2019-11-15 - gb\n",
      "INFO : 24/03/2020 08:18:34 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:34 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:36 PM : Extracting top 200 weekly for 2019-11-08--2019-11-15 - global\n",
      "INFO : 24/03/2020 08:18:36 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:36 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:38 PM : Extracting top 200 weekly for 2019-11-15--2019-11-22 - gb\n",
      "INFO : 24/03/2020 08:18:38 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:38 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:44 PM : Extracting top 200 weekly for 2019-11-15--2019-11-22 - global\n",
      "INFO : 24/03/2020 08:18:44 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:44 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:46 PM : Extracting top 200 weekly for 2019-11-22--2019-11-29 - gb\n",
      "INFO : 24/03/2020 08:18:46 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:46 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:50 PM : Extracting top 200 weekly for 2019-11-22--2019-11-29 - global\n",
      "INFO : 24/03/2020 08:18:50 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:50 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:52 PM : Extracting top 200 weekly for 2019-11-29--2019-12-06 - gb\n",
      "INFO : 24/03/2020 08:18:52 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:52 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:54 PM : Extracting top 200 weekly for 2019-11-29--2019-12-06 - global\n",
      "INFO : 24/03/2020 08:18:54 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:54 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:55 PM : Extracting top 200 weekly for 2019-12-06--2019-12-13 - gb\n",
      "INFO : 24/03/2020 08:18:55 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:55 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:57 PM : Extracting top 200 weekly for 2019-12-06--2019-12-13 - global\n",
      "INFO : 24/03/2020 08:18:57 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:57 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:18:59 PM : Extracting top 200 weekly for 2019-12-13--2019-12-20 - gb\n",
      "INFO : 24/03/2020 08:18:59 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:18:59 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:00 PM : Extracting top 200 weekly for 2019-12-13--2019-12-20 - global\n",
      "INFO : 24/03/2020 08:19:00 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:00 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:02 PM : Extracting top 200 weekly for 2019-12-20--2019-12-27 - gb\n",
      "INFO : 24/03/2020 08:19:02 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:02 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:03 PM : Extracting top 200 weekly for 2019-12-20--2019-12-27 - global\n",
      "INFO : 24/03/2020 08:19:03 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:03 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:05 PM : Extracting top 200 weekly for 2019-12-27--2020-01-03 - gb\n",
      "INFO : 24/03/2020 08:19:05 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:05 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:07 PM : Extracting top 200 weekly for 2019-12-27--2020-01-03 - global\n",
      "INFO : 24/03/2020 08:19:07 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:07 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:08 PM : Extracting top 200 weekly for 2020-01-03--2020-01-10 - gb\n",
      "INFO : 24/03/2020 08:19:08 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:08 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:11 PM : Extracting top 200 weekly for 2020-01-03--2020-01-10 - global\n",
      "INFO : 24/03/2020 08:19:11 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:11 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:13 PM : Extracting top 200 weekly for 2020-01-10--2020-01-17 - gb\n",
      "INFO : 24/03/2020 08:19:13 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:13 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:14 PM : Extracting top 200 weekly for 2020-01-10--2020-01-17 - global\n",
      "INFO : 24/03/2020 08:19:14 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:14 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:16 PM : Extracting top 200 weekly for 2020-01-17--2020-01-24 - gb\n",
      "INFO : 24/03/2020 08:19:16 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:16 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:21 PM : Extracting top 200 weekly for 2020-01-17--2020-01-24 - global\n",
      "INFO : 24/03/2020 08:19:21 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:21 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:22 PM : Extracting top 200 weekly for 2020-01-24--2020-01-31 - gb\n",
      "INFO : 24/03/2020 08:19:22 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:22 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:24 PM : Extracting top 200 weekly for 2020-01-24--2020-01-31 - global\n",
      "INFO : 24/03/2020 08:19:24 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:24 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:26 PM : Extracting top 200 weekly for 2020-01-31--2020-02-07 - gb\n",
      "INFO : 24/03/2020 08:19:26 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:26 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:28 PM : Extracting top 200 weekly for 2020-01-31--2020-02-07 - global\n",
      "INFO : 24/03/2020 08:19:28 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:28 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:30 PM : Extracting top 200 weekly for 2020-02-07--2020-02-14 - gb\n",
      "INFO : 24/03/2020 08:19:30 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:30 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:31 PM : Extracting top 200 weekly for 2020-02-07--2020-02-14 - global\n",
      "INFO : 24/03/2020 08:19:31 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:31 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:34 PM : Extracting top 200 weekly for 2020-02-14--2020-02-21 - gb\n",
      "INFO : 24/03/2020 08:19:34 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:34 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:35 PM : Extracting top 200 weekly for 2020-02-14--2020-02-21 - global\n",
      "INFO : 24/03/2020 08:19:35 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:35 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:37 PM : Extracting top 200 weekly for 2020-02-21--2020-02-28 - gb\n",
      "INFO : 24/03/2020 08:19:37 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:37 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:39 PM : Extracting top 200 weekly for 2020-02-21--2020-02-28 - global\n",
      "INFO : 24/03/2020 08:19:39 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:39 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n",
      "INFO : 24/03/2020 08:19:41 PM : Appending data to the file ../datasets/top_200_weekly.csv...\n",
      "INFO : 24/03/2020 08:19:41 PM : Done appending to the file ../datasets/top_200_weekly.csv!!!\n"
     ]
    }
   ],
   "source": [
    "#Run only when you want to fetch new date range\n",
    "api.top200Weekly(output_file = \"../datasets/top_200_weekly.csv\", start = \"2019-03-01\", end = \"2020-02-29\", region = [\"gb\", \"global\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate csv file\n",
    "import pandas as pd\n",
    "#use pandas to read file and save it again to remove blank lines\n",
    "df_weeklyTop200 = pd.read_csv('../datasets/top_200_weekly.csv')\n",
    "pandasToCSV(df_weeklyTop200, 'spotify_top_200_weekly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Streams</th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>spotify_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>101</td>\n",
       "      <td>BOP</td>\n",
       "      <td>DaBaby</td>\n",
       "      <td>536603</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>6Ozh9Ok6h4Oi1wUSLtBseN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20501</td>\n",
       "      <td>102</td>\n",
       "      <td>No Idea</td>\n",
       "      <td>Don Toliver</td>\n",
       "      <td>531490</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>3VyjsVV24RmBIbWJAeUJNu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20502</td>\n",
       "      <td>103</td>\n",
       "      <td>Still Disappointed</td>\n",
       "      <td>Stormzy</td>\n",
       "      <td>528289</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>78XK5PDIKWiDKcgiLl1x0o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20503</td>\n",
       "      <td>104</td>\n",
       "      <td>Must Be</td>\n",
       "      <td>J Hus</td>\n",
       "      <td>526226</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>5vIXEk3u02WHbcD0h2ozhm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20504</td>\n",
       "      <td>105</td>\n",
       "      <td>Thiago Silva</td>\n",
       "      <td>Dave</td>\n",
       "      <td>518335</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>3DKCTIiJ97bS9TGiqcABjo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20595</td>\n",
       "      <td>196</td>\n",
       "      <td>2002</td>\n",
       "      <td>Anne-Marie</td>\n",
       "      <td>359121</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>2BgEsaKNfHUdlh97KmvFyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20596</td>\n",
       "      <td>197</td>\n",
       "      <td>Dancing in the Moonlight</td>\n",
       "      <td>Toploader</td>\n",
       "      <td>357958</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>3Fzlg5r1IjhLk2qRw667od</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20597</td>\n",
       "      <td>198</td>\n",
       "      <td>Africa</td>\n",
       "      <td>TOTO</td>\n",
       "      <td>357620</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>2374M0fQpWi3dLnB54qaLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20598</td>\n",
       "      <td>199</td>\n",
       "      <td>Into the Unknown</td>\n",
       "      <td>Idina Menzel</td>\n",
       "      <td>357545</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>3Z0oQ8r78OUaHvGPiDBR3W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20599</td>\n",
       "      <td>200</td>\n",
       "      <td>God Is A Dancer (with Mabel)</td>\n",
       "      <td>Tiësto</td>\n",
       "      <td>357455</td>\n",
       "      <td>2020-02-21--2020-02-28</td>\n",
       "      <td>gb</td>\n",
       "      <td>6fenHIxXuuzKB55wY4WCHP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Position                    Track Name        Artist  Streams  \\\n",
       "20500       101                           BOP        DaBaby   536603   \n",
       "20501       102                       No Idea   Don Toliver   531490   \n",
       "20502       103            Still Disappointed       Stormzy   528289   \n",
       "20503       104                       Must Be         J Hus   526226   \n",
       "20504       105                  Thiago Silva          Dave   518335   \n",
       "...         ...                           ...           ...      ...   \n",
       "20595       196                          2002    Anne-Marie   359121   \n",
       "20596       197      Dancing in the Moonlight     Toploader   357958   \n",
       "20597       198                        Africa          TOTO   357620   \n",
       "20598       199              Into the Unknown  Idina Menzel   357545   \n",
       "20599       200  God Is A Dancer (with Mabel)        Tiësto   357455   \n",
       "\n",
       "                         date region              spotify_id  \n",
       "20500  2020-02-21--2020-02-28     gb  6Ozh9Ok6h4Oi1wUSLtBseN  \n",
       "20501  2020-02-21--2020-02-28     gb  3VyjsVV24RmBIbWJAeUJNu  \n",
       "20502  2020-02-21--2020-02-28     gb  78XK5PDIKWiDKcgiLl1x0o  \n",
       "20503  2020-02-21--2020-02-28     gb  5vIXEk3u02WHbcD0h2ozhm  \n",
       "20504  2020-02-21--2020-02-28     gb  3DKCTIiJ97bS9TGiqcABjo  \n",
       "...                       ...    ...                     ...  \n",
       "20595  2020-02-21--2020-02-28     gb  2BgEsaKNfHUdlh97KmvFyo  \n",
       "20596  2020-02-21--2020-02-28     gb  3Fzlg5r1IjhLk2qRw667od  \n",
       "20597  2020-02-21--2020-02-28     gb  2374M0fQpWi3dLnB54qaLX  \n",
       "20598  2020-02-21--2020-02-28     gb  3Z0oQ8r78OUaHvGPiDBR3W  \n",
       "20599  2020-02-21--2020-02-28     gb  6fenHIxXuuzKB55wY4WCHP  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gb_WeeklyTop200 =  df_weeklyTop200[df_weeklyTop200['region']== 'gb']\n",
    "df_gb_WeeklyTop200.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_uk_spotifyID = pd.unique(df_gb_WeeklyTop200[['spotify_id']].values.ravel('K'))\n",
    "len(unique_uk_spotifyID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_spotifyID = pd.unique(df_weeklyTop200[['spotify_id']].values.ravel('K'))\n",
    "len(unique_spotifyID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164f0d73-1234-4e2c-8743-d77bf2191051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://open.spotify.com/track/2wrJq5XKLnmhRXHIAf9xBa'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_id = mbSpot.get_artist_mbid('5K4W6rqBFWDnAN6FQUkS6x')\n",
    "print(mb_id)\n",
    "mbSpot.make_spotify_url('2wrJq5XKLnmhRXHIAf9xBa', spotify_type='track')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track = sp.track('2wrJq5XKLnmhRXHIAf9xBa')\n",
    "#2TIlqbIneP0ZY1O0EzYLlc\n",
    "#4S8d14HvHb70ImctNgVzQQ\n",
    "#df_track = pd.DataFrame(track)\n",
    "df_track = pd.DataFrame(track['artists'])\n",
    "df_track.head()\n",
    "track['popularity']\n",
    "#track['release_date_precision']\n",
    "str(track['popularity']) +' ==> ' + track['name'] + ' is_local= ' + str(track['is_local'] )\n",
    "str(track['album']['release_date'])\n",
    "str(track['album']['album_type'])\n",
    "\n",
    "#str(track['album']['id'])\n",
    "#track['duration_ms']\n",
    "#track['track_number']\n",
    "\n",
    "#track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Track_Info(trackID):\n",
    "    #df_track = pd.DataFrame(columns = ['track_spotifyID', 'id', 'name', 'artist_mbid'])\n",
    "    \n",
    "    try:\n",
    "        track = sp.track(trackID)   \n",
    "        df_track = pd.DataFrame(track['artists'])  \n",
    "        df_track = df_track.assign(track_spotifyID = trackID)\n",
    "        df_track = df_track.assign(artist_spotifyID = df_track['id'])\n",
    "        df_track = df_track.assign(artist_mbid = get_Artist_mbid(df_track))          \n",
    "        df_track = df_track.assign(artist_name = df_track['name'])        \n",
    "        df_track = df_track.assign(track_url = mbSpot.make_spotify_url(trackID, spotify_type='track'))     \n",
    "        \n",
    "        df_track = df_track.assign(track_popularity = track['popularity'])\n",
    "        df_track = df_track.assign(track_duration_ms = track['duration_ms'])\n",
    "        df_track = df_track.assign(track_is_local = track['is_local'])        \n",
    "        df_track = df_track.assign(albumID = track['album']['id'])\n",
    "        df_track = df_track.assign(album_track_number = track['track_number'])\n",
    "        df_track = df_track.assign(album_release_date = track['album']['release_date'])\n",
    "        df_track = df_track.assign(album_type = track['album']['album_type'])        \n",
    "       \n",
    "        df_track.drop(['external_urls','href', 'id', 'name', 'type', 'uri'], axis=1, inplace=True)\n",
    "\n",
    "        #df_track = df_track[['track_spotifyID','track_url', 'id', 'name', 'artist_mbid']]\n",
    "    except:\n",
    "        df_track = pd.DataFrame(columns = ['track_spotifyID'])\n",
    "\n",
    "    return df_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember to reference this project https://github.com/metabrainz/mbspotify\n",
    "import spotify2musicbrainz as mbSpot\n",
    "def get_Artist_mbid(df_artist):\n",
    "    ls_mbid=[]\n",
    "    for index, row in df_artist.iterrows(): \n",
    "        ls_mbid.append(mbSpot.get_artist_mbid(row['id']))\n",
    "        \n",
    "    return ls_mbid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value must have type '<class 'int'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-24ec1274b17c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_track\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Track_Info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'4kV4N9D1iKVxx1KLvtTpjS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_colwidth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_track\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_config\\config.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_config\\config.py\u001b[0m in \u001b[0;36m_set_option\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_registered_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# walk the nested dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_config\\config.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Value must have type '{typ!s}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Value must have type '<class 'int'>'"
     ]
    }
   ],
   "source": [
    "df_track = get_Track_Info('2wrJq5XKLnmhRXHIAf9xBa')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_track.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1===>2TIlqbIneP0ZY1O0EzYLlc\n",
      "2===>4kV4N9D1iKVxx1KLvtTpjS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "j = 0   \n",
    "cols = ['track_spotifyID', 'artist_spotifyID','artist_mbid','artist_name','track_url','track_popularity',\n",
    "        'track_duration_ms','track_is_local','albumID', 'album_track_number','album_release_date','album_type']\n",
    "df_track_details = pd.DataFrame(columns=cols)\n",
    "for x, value in np.ndenumerate(unique_spotifyID[:2]):\n",
    "    j += 1\n",
    "    df_t = get_Track_Info(value)\n",
    "    if not df_t.empty:\n",
    "        #print(df_t.head())\n",
    "        df_track_details = df_track_details.append(df_t, ignore_index=True)\n",
    "        print(str(j) + '===>' + value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate csv file\n",
    "pandasToCSV(df_track_details, 'spotify_track_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>track_spotifyID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_spotifyID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>00CMSJdbf36zOzKB3z8JrR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00FQb4jTyendYWaN8pK0wa</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00TKPo9MxwZ0j4ooveIxWZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00XhexlJEXQstHimpZN910</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00me4Ke1LsvMxt5kydlMyU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7wlFDEWiM5OoIAt8RSli8b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7xX15v6ahAkcT14kHfB9wB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7z2avKuuiMAT4XZJFv8Rvh</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7z5WFjZAIYejWy0NI5lv4T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7zoc6JsY8GWVcl2qFwiKay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>871 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       track_spotifyID\n",
       "                                 count\n",
       "artist_spotifyID                      \n",
       "00CMSJdbf36zOzKB3z8JrR               1\n",
       "00FQb4jTyendYWaN8pK0wa              14\n",
       "00TKPo9MxwZ0j4ooveIxWZ               1\n",
       "00XhexlJEXQstHimpZN910               3\n",
       "00me4Ke1LsvMxt5kydlMyU               1\n",
       "...                                ...\n",
       "7wlFDEWiM5OoIAt8RSli8b               2\n",
       "7xX15v6ahAkcT14kHfB9wB               1\n",
       "7z2avKuuiMAT4XZJFv8Rvh               5\n",
       "7z5WFjZAIYejWy0NI5lv4T               1\n",
       "7zoc6JsY8GWVcl2qFwiKay               1\n",
       "\n",
       "[871 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_track_details = pd.read_csv('../datasets/spotify_track_details.csv')\n",
    "#df_track_details.head(20)\n",
    "#df_filtered = df_track_details[(df_track_details.track_is_local == False) & (df_track_details.track_popularity > 95)]\n",
    "df_unique_artist = df_track_details[['artist_spotifyID','track_spotifyID']].groupby(['artist_spotifyID']).agg(['count'])\n",
    "df_unique_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_spotifyID</th>\n",
       "      <th>artist_spotifyID</th>\n",
       "      <th>artist_mbid</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_url</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_duration_ms</th>\n",
       "      <th>track_is_local</th>\n",
       "      <th>albumID</th>\n",
       "      <th>album_track_number</th>\n",
       "      <th>album_release_date</th>\n",
       "      <th>album_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1211</td>\n",
       "      <td>0vsrvBFFKrkyBWzrKADVkT</td>\n",
       "      <td>7b79bQFziJFedJb75k6hFt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tion Wayne</td>\n",
       "      <td>https://open.spotify.com/track/0vsrvBFFKrkyBWz...</td>\n",
       "      <td>48</td>\n",
       "      <td>200366</td>\n",
       "      <td>False</td>\n",
       "      <td>246r8XO9nlmQR1TfWZt6Am</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>573</td>\n",
       "      <td>0mFrbJniEwJcqzq3FQD14s</td>\n",
       "      <td>7b79bQFziJFedJb75k6hFt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tion Wayne</td>\n",
       "      <td>https://open.spotify.com/track/0mFrbJniEwJcqzq...</td>\n",
       "      <td>53</td>\n",
       "      <td>173617</td>\n",
       "      <td>False</td>\n",
       "      <td>7dG6Dl0UbiN7UpbPNSYh5T</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2904</td>\n",
       "      <td>0jgO2f0lAPSs36KBAHx9Dl</td>\n",
       "      <td>7b79bQFziJFedJb75k6hFt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tion Wayne</td>\n",
       "      <td>https://open.spotify.com/track/0jgO2f0lAPSs36K...</td>\n",
       "      <td>70</td>\n",
       "      <td>161118</td>\n",
       "      <td>False</td>\n",
       "      <td>4CDUyj6tjOqjZB2IDaLjol</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>5wIjM4q7oIgiLqn8Qfoyxh</td>\n",
       "      <td>7b79bQFziJFedJb75k6hFt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tion Wayne</td>\n",
       "      <td>https://open.spotify.com/track/5wIjM4q7oIgiLqn...</td>\n",
       "      <td>69</td>\n",
       "      <td>252906</td>\n",
       "      <td>False</td>\n",
       "      <td>5zab8YLQV8MOXSTpcK6mT3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-11</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1989</td>\n",
       "      <td>0RniiBbrT5QUD9TlZvlFGo</td>\n",
       "      <td>7b79bQFziJFedJb75k6hFt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tion Wayne</td>\n",
       "      <td>https://open.spotify.com/track/0RniiBbrT5QUD9T...</td>\n",
       "      <td>61</td>\n",
       "      <td>161140</td>\n",
       "      <td>False</td>\n",
       "      <td>5LinDhN1IU1e5bPckXCB4V</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2104</td>\n",
       "      <td>3gvop6gMwnUvGiCfY5iCJK</td>\n",
       "      <td>7cpCnhhBIU1gA7EhTFApN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerry Cinnamon</td>\n",
       "      <td>https://open.spotify.com/track/3gvop6gMwnUvGiC...</td>\n",
       "      <td>62</td>\n",
       "      <td>247250</td>\n",
       "      <td>False</td>\n",
       "      <td>6PH8j9lUH84RcVkbU5Q2Q8</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>4p9aWfBThbAeVuqhzFnBxl</td>\n",
       "      <td>7cpCnhhBIU1gA7EhTFApN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerry Cinnamon</td>\n",
       "      <td>https://open.spotify.com/track/4p9aWfBThbAeVuq...</td>\n",
       "      <td>66</td>\n",
       "      <td>266775</td>\n",
       "      <td>False</td>\n",
       "      <td>5iocpSTW9En8ndfSEHaF5E</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>2c9OnhCwDVpKZWjOPqKiA8</td>\n",
       "      <td>7cpCnhhBIU1gA7EhTFApN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerry Cinnamon</td>\n",
       "      <td>https://open.spotify.com/track/2c9OnhCwDVpKZWj...</td>\n",
       "      <td>67</td>\n",
       "      <td>196600</td>\n",
       "      <td>False</td>\n",
       "      <td>6fyMUlF3m4s4aMrbpT6HIL</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1283</td>\n",
       "      <td>3buZ8XXWl8OJriJXL48XJc</td>\n",
       "      <td>7cpCnhhBIU1gA7EhTFApN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerry Cinnamon</td>\n",
       "      <td>https://open.spotify.com/track/3buZ8XXWl8OJriJ...</td>\n",
       "      <td>67</td>\n",
       "      <td>194000</td>\n",
       "      <td>False</td>\n",
       "      <td>6fyMUlF3m4s4aMrbpT6HIL</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3021</td>\n",
       "      <td>2Funh8wU3oKKk2jkmjLIkD</td>\n",
       "      <td>7cpCnhhBIU1gA7EhTFApN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerry Cinnamon</td>\n",
       "      <td>https://open.spotify.com/track/2Funh8wU3oKKk2j...</td>\n",
       "      <td>64</td>\n",
       "      <td>240330</td>\n",
       "      <td>False</td>\n",
       "      <td>3yU6K9E3iUWRpZzV09V8Ru</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1196</td>\n",
       "      <td>6EBlOYNcZ8MrdEov9lEdV6</td>\n",
       "      <td>7hOGhpa8RMSuDOWntGIAJt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A R I Z O N A</td>\n",
       "      <td>https://open.spotify.com/track/6EBlOYNcZ8MrdEo...</td>\n",
       "      <td>68</td>\n",
       "      <td>171785</td>\n",
       "      <td>False</td>\n",
       "      <td>6Ad1E9vl75ZB3Ir87zwXIJ</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>7cz506PyIgh2bMN90Mc8Tn</td>\n",
       "      <td>7k9T7lZlHjRAM1bb0r9Rm3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>https://open.spotify.com/track/7cz506PyIgh2bMN...</td>\n",
       "      <td>72</td>\n",
       "      <td>177185</td>\n",
       "      <td>False</td>\n",
       "      <td>7JoyVaXzxpgTPjkgB8mWk3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1393</td>\n",
       "      <td>3zgKEF4I4ILmTTSBvtiRlJ</td>\n",
       "      <td>7k9T7lZlHjRAM1bb0r9Rm3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>https://open.spotify.com/track/3zgKEF4I4ILmTTS...</td>\n",
       "      <td>62</td>\n",
       "      <td>186874</td>\n",
       "      <td>False</td>\n",
       "      <td>1bE9v4U6xT3MDCh2SPn3jH</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2237</td>\n",
       "      <td>13lgFanIzQVjIiVvxyAjjS</td>\n",
       "      <td>7oNsk0nkBTccrd9DTdeiPc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Cast of RuPaul's Drag Race UK</td>\n",
       "      <td>https://open.spotify.com/track/13lgFanIzQVjIiV...</td>\n",
       "      <td>53</td>\n",
       "      <td>151825</td>\n",
       "      <td>False</td>\n",
       "      <td>4vydhCuNsBlq3S4PNCO5K6</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599</td>\n",
       "      <td>7o0oY5wRcoV7oPuDhD2J1z</td>\n",
       "      <td>7rOlQwf8OuFLFQp4aydjBt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paloma Mami</td>\n",
       "      <td>https://open.spotify.com/track/7o0oY5wRcoV7oPu...</td>\n",
       "      <td>69</td>\n",
       "      <td>225373</td>\n",
       "      <td>False</td>\n",
       "      <td>1V2sg9XB2TP29Ys4ER3fLn</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1962</td>\n",
       "      <td>1KdwnsWOvhM53vezy5ROuf</td>\n",
       "      <td>7rOlQwf8OuFLFQp4aydjBt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paloma Mami</td>\n",
       "      <td>https://open.spotify.com/track/1KdwnsWOvhM53ve...</td>\n",
       "      <td>73</td>\n",
       "      <td>182815</td>\n",
       "      <td>False</td>\n",
       "      <td>1VIVJSQidZ6nddSJoEEYt7</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2117</td>\n",
       "      <td>6klLvorLoo1sxvZcjJIY8I</td>\n",
       "      <td>7wlFDEWiM5OoIAt8RSli8b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td>https://open.spotify.com/track/6klLvorLoo1sxvZ...</td>\n",
       "      <td>81</td>\n",
       "      <td>148629</td>\n",
       "      <td>False</td>\n",
       "      <td>1nzUj7VkiaytMmf2KrhK2L</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2054</td>\n",
       "      <td>6Gg1gjgKi2AK4e0qzsR7sd</td>\n",
       "      <td>7wlFDEWiM5OoIAt8RSli8b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td>https://open.spotify.com/track/6Gg1gjgKi2AK4e0...</td>\n",
       "      <td>87</td>\n",
       "      <td>189322</td>\n",
       "      <td>False</td>\n",
       "      <td>3t6Z2qoBVCS4NHNI25XECH</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2295</td>\n",
       "      <td>5C0ivQMxes2lWuOANhvVAm</td>\n",
       "      <td>7xX15v6ahAkcT14kHfB9wB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True Damage</td>\n",
       "      <td>https://open.spotify.com/track/5C0ivQMxes2lWuO...</td>\n",
       "      <td>72</td>\n",
       "      <td>191720</td>\n",
       "      <td>False</td>\n",
       "      <td>1hK1lKNTYUM4wYRIY19CRO</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>3JDLEkyVTDKyJLy5CNMTaB</td>\n",
       "      <td>7zoc6JsY8GWVcl2qFwiKay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Talia Mar</td>\n",
       "      <td>https://open.spotify.com/track/3JDLEkyVTDKyJLy...</td>\n",
       "      <td>53</td>\n",
       "      <td>176842</td>\n",
       "      <td>False</td>\n",
       "      <td>7oRqm6Jobe0auS3zH8Ey63</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             track_spotifyID        artist_spotifyID artist_mbid  \\\n",
       "1211  0vsrvBFFKrkyBWzrKADVkT  7b79bQFziJFedJb75k6hFt         NaN   \n",
       "573   0mFrbJniEwJcqzq3FQD14s  7b79bQFziJFedJb75k6hFt         NaN   \n",
       "2904  0jgO2f0lAPSs36KBAHx9Dl  7b79bQFziJFedJb75k6hFt         NaN   \n",
       "705   5wIjM4q7oIgiLqn8Qfoyxh  7b79bQFziJFedJb75k6hFt         NaN   \n",
       "1989  0RniiBbrT5QUD9TlZvlFGo  7b79bQFziJFedJb75k6hFt         NaN   \n",
       "2104  3gvop6gMwnUvGiCfY5iCJK  7cpCnhhBIU1gA7EhTFApN1         NaN   \n",
       "1265  4p9aWfBThbAeVuqhzFnBxl  7cpCnhhBIU1gA7EhTFApN1         NaN   \n",
       "1660  2c9OnhCwDVpKZWjOPqKiA8  7cpCnhhBIU1gA7EhTFApN1         NaN   \n",
       "1283  3buZ8XXWl8OJriJXL48XJc  7cpCnhhBIU1gA7EhTFApN1         NaN   \n",
       "3021  2Funh8wU3oKKk2jkmjLIkD  7cpCnhhBIU1gA7EhTFApN1         NaN   \n",
       "1196  6EBlOYNcZ8MrdEov9lEdV6  7hOGhpa8RMSuDOWntGIAJt         NaN   \n",
       "291   7cz506PyIgh2bMN90Mc8Tn  7k9T7lZlHjRAM1bb0r9Rm3         NaN   \n",
       "1393  3zgKEF4I4ILmTTSBvtiRlJ  7k9T7lZlHjRAM1bb0r9Rm3         NaN   \n",
       "2237  13lgFanIzQVjIiVvxyAjjS  7oNsk0nkBTccrd9DTdeiPc         NaN   \n",
       "599   7o0oY5wRcoV7oPuDhD2J1z  7rOlQwf8OuFLFQp4aydjBt         NaN   \n",
       "1962  1KdwnsWOvhM53vezy5ROuf  7rOlQwf8OuFLFQp4aydjBt         NaN   \n",
       "2117  6klLvorLoo1sxvZcjJIY8I  7wlFDEWiM5OoIAt8RSli8b         NaN   \n",
       "2054  6Gg1gjgKi2AK4e0qzsR7sd  7wlFDEWiM5OoIAt8RSli8b         NaN   \n",
       "2295  5C0ivQMxes2lWuOANhvVAm  7xX15v6ahAkcT14kHfB9wB         NaN   \n",
       "728   3JDLEkyVTDKyJLy5CNMTaB  7zoc6JsY8GWVcl2qFwiKay         NaN   \n",
       "\n",
       "                            artist_name  \\\n",
       "1211                         Tion Wayne   \n",
       "573                          Tion Wayne   \n",
       "2904                         Tion Wayne   \n",
       "705                          Tion Wayne   \n",
       "1989                         Tion Wayne   \n",
       "2104                     Gerry Cinnamon   \n",
       "1265                     Gerry Cinnamon   \n",
       "1660                     Gerry Cinnamon   \n",
       "1283                     Gerry Cinnamon   \n",
       "3021                     Gerry Cinnamon   \n",
       "1196                      A R I Z O N A   \n",
       "291                               Wiley   \n",
       "1393                              Wiley   \n",
       "2237  The Cast of RuPaul's Drag Race UK   \n",
       "599                         Paloma Mami   \n",
       "1962                        Paloma Mami   \n",
       "2117         YoungBoy Never Broke Again   \n",
       "2054         YoungBoy Never Broke Again   \n",
       "2295                        True Damage   \n",
       "728                           Talia Mar   \n",
       "\n",
       "                                              track_url  track_popularity  \\\n",
       "1211  https://open.spotify.com/track/0vsrvBFFKrkyBWz...                48   \n",
       "573   https://open.spotify.com/track/0mFrbJniEwJcqzq...                53   \n",
       "2904  https://open.spotify.com/track/0jgO2f0lAPSs36K...                70   \n",
       "705   https://open.spotify.com/track/5wIjM4q7oIgiLqn...                69   \n",
       "1989  https://open.spotify.com/track/0RniiBbrT5QUD9T...                61   \n",
       "2104  https://open.spotify.com/track/3gvop6gMwnUvGiC...                62   \n",
       "1265  https://open.spotify.com/track/4p9aWfBThbAeVuq...                66   \n",
       "1660  https://open.spotify.com/track/2c9OnhCwDVpKZWj...                67   \n",
       "1283  https://open.spotify.com/track/3buZ8XXWl8OJriJ...                67   \n",
       "3021  https://open.spotify.com/track/2Funh8wU3oKKk2j...                64   \n",
       "1196  https://open.spotify.com/track/6EBlOYNcZ8MrdEo...                68   \n",
       "291   https://open.spotify.com/track/7cz506PyIgh2bMN...                72   \n",
       "1393  https://open.spotify.com/track/3zgKEF4I4ILmTTS...                62   \n",
       "2237  https://open.spotify.com/track/13lgFanIzQVjIiV...                53   \n",
       "599   https://open.spotify.com/track/7o0oY5wRcoV7oPu...                69   \n",
       "1962  https://open.spotify.com/track/1KdwnsWOvhM53ve...                73   \n",
       "2117  https://open.spotify.com/track/6klLvorLoo1sxvZ...                81   \n",
       "2054  https://open.spotify.com/track/6Gg1gjgKi2AK4e0...                87   \n",
       "2295  https://open.spotify.com/track/5C0ivQMxes2lWuO...                72   \n",
       "728   https://open.spotify.com/track/3JDLEkyVTDKyJLy...                53   \n",
       "\n",
       "      track_duration_ms  track_is_local                 albumID  \\\n",
       "1211             200366           False  246r8XO9nlmQR1TfWZt6Am   \n",
       "573              173617           False  7dG6Dl0UbiN7UpbPNSYh5T   \n",
       "2904             161118           False  4CDUyj6tjOqjZB2IDaLjol   \n",
       "705              252906           False  5zab8YLQV8MOXSTpcK6mT3   \n",
       "1989             161140           False  5LinDhN1IU1e5bPckXCB4V   \n",
       "2104             247250           False  6PH8j9lUH84RcVkbU5Q2Q8   \n",
       "1265             266775           False  5iocpSTW9En8ndfSEHaF5E   \n",
       "1660             196600           False  6fyMUlF3m4s4aMrbpT6HIL   \n",
       "1283             194000           False  6fyMUlF3m4s4aMrbpT6HIL   \n",
       "3021             240330           False  3yU6K9E3iUWRpZzV09V8Ru   \n",
       "1196             171785           False  6Ad1E9vl75ZB3Ir87zwXIJ   \n",
       "291              177185           False  7JoyVaXzxpgTPjkgB8mWk3   \n",
       "1393             186874           False  1bE9v4U6xT3MDCh2SPn3jH   \n",
       "2237             151825           False  4vydhCuNsBlq3S4PNCO5K6   \n",
       "599              225373           False  1V2sg9XB2TP29Ys4ER3fLn   \n",
       "1962             182815           False  1VIVJSQidZ6nddSJoEEYt7   \n",
       "2117             148629           False  1nzUj7VkiaytMmf2KrhK2L   \n",
       "2054             189322           False  3t6Z2qoBVCS4NHNI25XECH   \n",
       "2295             191720           False  1hK1lKNTYUM4wYRIY19CRO   \n",
       "728              176842           False  7oRqm6Jobe0auS3zH8Ey63   \n",
       "\n",
       "      album_track_number album_release_date album_type  \n",
       "1211                   1         2019-06-13     single  \n",
       "573                    1         2019-03-21     single  \n",
       "2904                   1         2020-02-06     single  \n",
       "705                    1         2019-04-11     single  \n",
       "1989                   8         2019-09-27      album  \n",
       "2104                   1         2019-10-11     single  \n",
       "1265                   1         2019-06-22     single  \n",
       "1660                   1         2017-09-28      album  \n",
       "1283                   4         2017-09-28      album  \n",
       "3021                   1         2020-02-21     single  \n",
       "1196                   7         2019-06-06      album  \n",
       "291                    1         2019-01-22     single  \n",
       "1393                   1         2019-07-05     single  \n",
       "2237                   1         2019-10-31     single  \n",
       "599                    1         2019-03-22     single  \n",
       "1962                   1         2019-09-12     single  \n",
       "2117                   6         2019-10-11      album  \n",
       "2054                   1         2019-10-04     single  \n",
       "2295                   1         2019-11-10     single  \n",
       "728                    5         2019-04-12      album  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_track_details[(df_track_details.artist_mbid != '')]\n",
    "\n",
    "df_null_mbid = df_track_details[df_track_details['artist_mbid'].isnull()]\n",
    "df_null_mbid.sort_values('artist_spotifyID', ascending = True).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>track_spotifyID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_spotifyID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>00CMSJdbf36zOzKB3z8JrR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00me4Ke1LsvMxt5kydlMyU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0AkL5tzM3UsDlWak9E0OwH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0CqfkYr7CBuSySa4wUBChE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0ErzCpIMyLcjPiwT4elrtZ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0GM7qgcRCORpGnfcN2tCiB</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0GOx72r5AAEKRGQFn3xqXK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0H39MdGGX6dbnnQPt6NQkZ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0HU0U9kdXEHZVxUNbuQe8S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0HkcYmcjrBR3SCw9Ld5VZk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       track_spotifyID\n",
       "                                 count\n",
       "artist_spotifyID                      \n",
       "00CMSJdbf36zOzKB3z8JrR               1\n",
       "00me4Ke1LsvMxt5kydlMyU               1\n",
       "0AkL5tzM3UsDlWak9E0OwH               2\n",
       "0CqfkYr7CBuSySa4wUBChE               1\n",
       "0ErzCpIMyLcjPiwT4elrtZ               4\n",
       "0GM7qgcRCORpGnfcN2tCiB               4\n",
       "0GOx72r5AAEKRGQFn3xqXK               1\n",
       "0H39MdGGX6dbnnQPt6NQkZ               2\n",
       "0HU0U9kdXEHZVxUNbuQe8S               1\n",
       "0HkcYmcjrBR3SCw9Ld5VZk               2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null = df_null_mbid[['artist_spotifyID','track_spotifyID']].groupby(['artist_spotifyID']).agg(['count'])\n",
    "df_null.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Streams</th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>spotify_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Someone You Loved</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>3338234</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>2TIlqbIneP0ZY1O0EzYLlc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>break up with your girlfriend, i'm bored</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>3041558</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>4kV4N9D1iKVxx1KLvtTpjS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Giant (with Rag'n'Bone Man)</td>\n",
       "      <td>Calvin Harris</td>\n",
       "      <td>2846784</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>5itOtNx0WxtJmi1TQ3RuRd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>2836252</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>6ocbgoVGwYJhOv1GgI9NsF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Don't Call Me Up</td>\n",
       "      <td>Mabel</td>\n",
       "      <td>2783485</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>5WHTFyqSii0lmT9R21abT8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Wow.</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>2488501</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>6MWtB6iiXyIwun0YzU6DFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Sucker</td>\n",
       "      <td>Jonas Brothers</td>\n",
       "      <td>2190914</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>4y3OI86AEP6PQoDE6olYhO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Dancing With A Stranger (with Normani)</td>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>2041358</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>6Qs4SXO9dwPj5GKvVOv8Ki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Shallow</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>1984056</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>2VxeLyX666F8uXCJ0dZF8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Options</td>\n",
       "      <td>NSG</td>\n",
       "      <td>1933493</td>\n",
       "      <td>2019-03-01--2019-03-08</td>\n",
       "      <td>gb</td>\n",
       "      <td>2cytBOLpwFRX7J9URCrFIe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position                                Track Name          Artist  \\\n",
       "0         1                         Someone You Loved   Lewis Capaldi   \n",
       "1         2  break up with your girlfriend, i'm bored   Ariana Grande   \n",
       "2         3               Giant (with Rag'n'Bone Man)   Calvin Harris   \n",
       "3         4                                   7 rings   Ariana Grande   \n",
       "4         5                          Don't Call Me Up           Mabel   \n",
       "5         6                                      Wow.     Post Malone   \n",
       "6         7                                    Sucker  Jonas Brothers   \n",
       "7         8    Dancing With A Stranger (with Normani)       Sam Smith   \n",
       "8         9                                   Shallow       Lady Gaga   \n",
       "9        10                                   Options             NSG   \n",
       "\n",
       "   Streams                    date region              spotify_id  \n",
       "0  3338234  2019-03-01--2019-03-08     gb  2TIlqbIneP0ZY1O0EzYLlc  \n",
       "1  3041558  2019-03-01--2019-03-08     gb  4kV4N9D1iKVxx1KLvtTpjS  \n",
       "2  2846784  2019-03-01--2019-03-08     gb  5itOtNx0WxtJmi1TQ3RuRd  \n",
       "3  2836252  2019-03-01--2019-03-08     gb  6ocbgoVGwYJhOv1GgI9NsF  \n",
       "4  2783485  2019-03-01--2019-03-08     gb  5WHTFyqSii0lmT9R21abT8  \n",
       "5  2488501  2019-03-01--2019-03-08     gb  6MWtB6iiXyIwun0YzU6DFP  \n",
       "6  2190914  2019-03-01--2019-03-08     gb  4y3OI86AEP6PQoDE6olYhO  \n",
       "7  2041358  2019-03-01--2019-03-08     gb  6Qs4SXO9dwPj5GKvVOv8Ki  \n",
       "8  1984056  2019-03-01--2019-03-08     gb  2VxeLyX666F8uXCJ0dZF8B  \n",
       "9  1933493  2019-03-01--2019-03-08     gb  2cytBOLpwFRX7J9URCrFIe  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weeklyTop200.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spotify_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">gb</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21 Savage</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24kGoldn</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5 Seconds of Summer</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6ix9ine</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           spotify_id\n",
       "                                count\n",
       "region Artist                        \n",
       "gb     *NSYNC                       1\n",
       "       21 Savage                    7\n",
       "       24kGoldn                     2\n",
       "       5 Seconds of Summer         62\n",
       "       6ix9ine                      7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkk = df_weeklyTop200[['region', 'Artist', 'spotify_id']].groupby(['region','Artist']).agg(['count'])#.sort_values('count', ascending=False)\n",
    "gkk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Position</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Track Name</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Streams</th>\n",
       "      <th colspan=\"4\" halign=\"left\">date</th>\n",
       "      <th colspan=\"4\" halign=\"left\">spotify_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">gb</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.00</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.00</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.13e+05</td>\n",
       "      <td>7.13e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-20--2019-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2il7ZxLzVhPxMHNidnsa3I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21 Savage</td>\n",
       "      <td>7.0</td>\n",
       "      <td>114.14</td>\n",
       "      <td>46.07</td>\n",
       "      <td>50.0</td>\n",
       "      <td>82.50</td>\n",
       "      <td>119.0</td>\n",
       "      <td>141.50</td>\n",
       "      <td>182.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.69e+05</td>\n",
       "      <td>7.45e+05</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-03-15--2019-03-22</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2t8yVaLvJ0RenpXUIAC52d</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24kGoldn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>29.70</td>\n",
       "      <td>46.0</td>\n",
       "      <td>56.50</td>\n",
       "      <td>67.0</td>\n",
       "      <td>77.50</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.64e+05</td>\n",
       "      <td>8.23e+05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-14--2020-02-21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6ap9lSRJ0iLriGLqoJ44cq</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5 Seconds of Summer</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.21</td>\n",
       "      <td>42.35</td>\n",
       "      <td>37.0</td>\n",
       "      <td>102.75</td>\n",
       "      <td>128.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>199.0</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.15e+05</td>\n",
       "      <td>1.00e+06</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>2019-08-23--2019-08-30</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>2iUXsYOEPhVqEBwsqP70rE</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6ix9ine</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.71</td>\n",
       "      <td>20.88</td>\n",
       "      <td>129.0</td>\n",
       "      <td>144.50</td>\n",
       "      <td>157.0</td>\n",
       "      <td>160.50</td>\n",
       "      <td>194.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.32e+05</td>\n",
       "      <td>4.66e+05</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-03-15--2019-03-22</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6Gy7rXB6Ku5vIWC7WGWsl3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">global</td>\n",
       "      <td>Zedd</td>\n",
       "      <td>39.0</td>\n",
       "      <td>140.10</td>\n",
       "      <td>40.23</td>\n",
       "      <td>53.0</td>\n",
       "      <td>122.00</td>\n",
       "      <td>153.0</td>\n",
       "      <td>168.50</td>\n",
       "      <td>186.0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.84e+06</td>\n",
       "      <td>8.49e+06</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>2019-03-15--2019-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>09IStsImFySgyp0pIQdqAc</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>benny blanco</td>\n",
       "      <td>66.0</td>\n",
       "      <td>89.94</td>\n",
       "      <td>39.17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>61.25</td>\n",
       "      <td>85.0</td>\n",
       "      <td>121.75</td>\n",
       "      <td>174.0</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8.89e+06</td>\n",
       "      <td>1.61e+07</td>\n",
       "      <td>66</td>\n",
       "      <td>51</td>\n",
       "      <td>2019-03-08--2019-03-15</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>7FGq80cy8juXBCD2nrqdWU</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>blackbear</td>\n",
       "      <td>33.0</td>\n",
       "      <td>49.55</td>\n",
       "      <td>45.02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.69e+07</td>\n",
       "      <td>2.08e+07</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>2020-02-07--2020-02-14</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>7aiClxsDWFRQ0Kzk5KI5ku</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>j-hope</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.93e+06</td>\n",
       "      <td>5.93e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-27--2019-10-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6wyr4ReB05D9sJB1Rsmcqo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tha Supreme</td>\n",
       "      <td>4.0</td>\n",
       "      <td>106.25</td>\n",
       "      <td>51.32</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>142.25</td>\n",
       "      <td>164.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.47e+06</td>\n",
       "      <td>7.61e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-11-15--2019-11-22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7HwvPmK74MBRDhCIyMXReP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Position                                       \\\n",
       "                              count    mean    std    min     25%    50%   \n",
       "region Artist                                                              \n",
       "gb     *NSYNC                   1.0  134.00    NaN  134.0  134.00  134.0   \n",
       "       21 Savage                7.0  114.14  46.07   50.0   82.50  119.0   \n",
       "       24kGoldn                 2.0   67.00  29.70   46.0   56.50   67.0   \n",
       "       5 Seconds of Summer     62.0  126.21  42.35   37.0  102.75  128.0   \n",
       "       6ix9ine                  7.0  155.71  20.88  129.0  144.50  157.0   \n",
       "...                             ...     ...    ...    ...     ...    ...   \n",
       "global Zedd                    39.0  140.10  40.23   53.0  122.00  153.0   \n",
       "       benny blanco            66.0   89.94  39.17   21.0   61.25   85.0   \n",
       "       blackbear               33.0   49.55  45.02    9.0   18.00   33.0   \n",
       "       j-hope                   1.0  114.00    NaN  114.0  114.00  114.0   \n",
       "       tha Supreme              4.0  106.25  51.32   63.0   63.00   99.0   \n",
       "\n",
       "                                          Track Name         ...   Streams  \\\n",
       "                               75%    max      count unique  ...       75%   \n",
       "region Artist                                                ...             \n",
       "gb     *NSYNC               134.00  134.0          1      1  ...  7.13e+05   \n",
       "       21 Savage            141.50  182.0          7      1  ...  5.69e+05   \n",
       "       24kGoldn              77.50   88.0          2      1  ...  7.64e+05   \n",
       "       5 Seconds of Summer  156.75  199.0         62      5  ...  5.15e+05   \n",
       "       6ix9ine              160.50  194.0          7      1  ...  4.32e+05   \n",
       "...                            ...    ...        ...    ...  ...       ...   \n",
       "global Zedd                 168.50  186.0         39      3  ...  5.84e+06   \n",
       "       benny blanco         121.75  174.0         66      3  ...  8.89e+06   \n",
       "       blackbear             65.00  160.0         33      2  ...  1.69e+07   \n",
       "       j-hope               114.00  114.0          1      1  ...  5.93e+06   \n",
       "       tha Supreme          142.25  164.0          4      2  ...  7.47e+06   \n",
       "\n",
       "                                      date                                 \\\n",
       "                                 max count unique                     top   \n",
       "region Artist                                                               \n",
       "gb     *NSYNC               7.13e+05     1      1  2019-12-20--2019-12-27   \n",
       "       21 Savage            7.45e+05     7      7  2019-03-15--2019-03-22   \n",
       "       24kGoldn             8.23e+05     2      2  2020-02-14--2020-02-21   \n",
       "       5 Seconds of Summer  1.00e+06    62     39  2019-08-23--2019-08-30   \n",
       "       6ix9ine              4.66e+05     7      7  2019-03-15--2019-03-22   \n",
       "...                              ...   ...    ...                     ...   \n",
       "global Zedd                 8.49e+06    39     34  2019-03-15--2019-03-22   \n",
       "       benny blanco         1.61e+07    66     51  2019-03-08--2019-03-15   \n",
       "       blackbear            2.08e+07    33     27  2020-02-07--2020-02-14   \n",
       "       j-hope               5.93e+06     1      1  2019-09-27--2019-10-04   \n",
       "       tha Supreme          7.61e+06     4      3  2019-11-15--2019-11-22   \n",
       "\n",
       "                                spotify_id                                      \n",
       "                           freq      count unique                     top freq  \n",
       "region Artist                                                                   \n",
       "gb     *NSYNC                 1          1      1  2il7ZxLzVhPxMHNidnsa3I    1  \n",
       "       21 Savage              1          7      1  2t8yVaLvJ0RenpXUIAC52d    7  \n",
       "       24kGoldn               1          2      1  6ap9lSRJ0iLriGLqoJ44cq    2  \n",
       "       5 Seconds of Summer    3         62      5  2iUXsYOEPhVqEBwsqP70rE   36  \n",
       "       6ix9ine                1          7      1  6Gy7rXB6Ku5vIWC7WGWsl3    7  \n",
       "...                         ...        ...    ...                     ...  ...  \n",
       "global Zedd                   2         39      3  09IStsImFySgyp0pIQdqAc   25  \n",
       "       benny blanco           2         66      3  7FGq80cy8juXBCD2nrqdWU   51  \n",
       "       blackbear              2         33      2  7aiClxsDWFRQ0Kzk5KI5ku   27  \n",
       "       j-hope                 1          1      1  6wyr4ReB05D9sJB1Rsmcqo    1  \n",
       "       tha Supreme            2          4      3  7HwvPmK74MBRDhCIyMXReP    2  \n",
       "\n",
       "[792 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('precision', 2):\n",
    "    display(df_weeklyTop200.groupby(['region', 'Artist'])\n",
    "               .describe(include='all')\n",
    "               .dropna(how='all', axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
